# pages/10_Correlaciones.py

import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import json

st.set_page_config(
    page_title="An치lisis de Correlaciones",
    page_icon="游늵",
    layout="wide",
)

st.write("# An치lisis de Correlaciones 游늵")

st.markdown("""
Explora las correlaciones entre diferentes variables en los datos de F칩rmula 1.
""")

# ---------------------------
# Cargar datasets
@st.cache_data
def load_data():
    drivers = pd.read_csv('data/drivers.csv')
    constructors = pd.read_csv('data/constructors.csv')
    results = pd.read_csv('data/results.csv')
    races = pd.read_csv('data/races.csv')
    circuits = pd.read_csv('data/circuits.csv')
    lap_times = pd.read_csv('data/lap_times.csv')
    pit_stops = pd.read_csv('data/pit_stops.csv')
    qualifying = pd.read_csv('data/qualifying.csv')
    seasons = pd.read_csv('data/seasons.csv')
    driver_standings = pd.read_csv('data/driver_standings.csv')
    constructor_standings = pd.read_csv('data/constructor_standings.csv')
    constructor_results = pd.read_csv('data/constructor_results.csv')
    sprint_results = pd.read_csv('data/sprint_results.csv')
    status = pd.read_csv('data/status.csv')
    # No cargamos weather data

    # Cargar datos desde los archivos JSON
    with open('data/surface_classification.json', 'r') as f:
        surface_classification = json.load(f)

    with open('data/permanence_classification.json', 'r') as f:
        permanence_classification = json.load(f)

    with open('data/continent_classification.json', 'r') as f:
        continent_classification = json.load(f)

    with open('data/circuit_lengths.json', 'r') as f:
        circuit_lengths = json.load(f)

    return {
        'drivers': drivers,
        'constructors': constructors,
        'results': results,
        'races': races,
        'circuits': circuits,
        'lap_times': lap_times,
        'pit_stops': pit_stops,
        'qualifying': qualifying,
        'seasons': seasons,
        'driver_standings': driver_standings,
        'constructor_standings': constructor_standings,
        'constructor_results': constructor_results,
        'sprint_results': sprint_results,
        'status': status,
        'surface_classification': surface_classification,
        'permanence_classification': permanence_classification,
        'continent_classification': continent_classification,
        'circuit_lengths': circuit_lengths
    }

data = load_data()

# ---------------------------
# Preparar los datos para el an치lisis

# Reemplazar valores no num칠ricos
for df_name in ['results', 'qualifying', 'lap_times', 'pit_stops']:
    data[df_name].replace('\\N', np.nan, inplace=True)

# Convertir columnas num칠ricas a tipos apropiados
numeric_cols_results = ['grid', 'positionOrder', 'position', 'points', 'laps', 'milliseconds', 'fastestLapSpeed']
data['results'][numeric_cols_results] = data['results'][numeric_cols_results].apply(pd.to_numeric, errors='coerce')

numeric_cols_qualifying = ['position', 'q1', 'q2', 'q3']
data['qualifying'][numeric_cols_qualifying] = data['qualifying'][numeric_cols_qualifying].apply(pd.to_numeric, errors='coerce')

# Merge de datasets relevantes
results = data['results']
races = data['races']
drivers = data['drivers']
constructors = data['constructors']
pit_stops = data['pit_stops']
circuits = data['circuits']

# Unir 'results' con 'races'
results_races = pd.merge(results, races[['raceId', 'year', 'name', 'date', 'circuitId']], on='raceId', how='left')

# Unir con 'drivers'
results_races_drivers = pd.merge(results_races, drivers[['driverId', 'driverRef', 'forename', 'surname', 'dob', 'nationality']], on='driverId', how='left')

# Unir con 'constructors'
results_races_drivers = pd.merge(results_races_drivers, constructors[['constructorId', 'name']], on='constructorId', how='left', suffixes=('', '_constructor'))

# Unir con 'qualifying' para obtener posici칩n de clasificaci칩n
qualifying = data['qualifying']
results_races_drivers = pd.merge(results_races_drivers, qualifying[['raceId', 'driverId', 'position']], on=['raceId', 'driverId'], how='left', suffixes=('', '_qualifying'))

# Renombrar 'position' de clasificaci칩n a 'posicion_clasificacion'
results_races_drivers.rename(columns={'position_qualifying': 'posicion_clasificacion'}, inplace=True)

# Calcular la edad del piloto en el momento de la carrera
results_races_drivers['dob'] = pd.to_datetime(results_races_drivers['dob'], errors='coerce')
results_races_drivers['date'] = pd.to_datetime(results_races_drivers['date'], errors='coerce')
results_races_drivers['edad_piloto'] = (results_races_drivers['date'] - results_races_drivers['dob']).dt.days / 365.25

# Calcular el n칰mero total de pit stops por piloto en cada carrera
pit_stops_per_driver = data['pit_stops'].groupby(['raceId', 'driverId']).size().reset_index(name='num_pit_stops')

# Unir con el dataset principal
results_races_drivers = pd.merge(results_races_drivers, pit_stops_per_driver, on=['raceId', 'driverId'], how='left')

# Reemplazar NaN en 'num_pit_stops' por 0
results_races_drivers['num_pit_stops'] = results_races_drivers['num_pit_stops'].fillna(0)

# A침adir informaci칩n de circuitos
# A침adir longitud del circuito desde 'circuit_lengths'
# Convertir 'circuit_lengths' de JSON a DataFrame
circuit_lengths_df = pd.DataFrame.from_dict(data['circuit_lengths'], orient='index', columns=['circuit_length_km'])
circuit_lengths_df.reset_index(inplace=True)
circuit_lengths_df.rename(columns={'index': 'circuitRef'}, inplace=True)
circuit_lengths_df['circuit_length_km'] = pd.to_numeric(circuit_lengths_df['circuit_length_km'], errors='coerce')

# Unir 'circuits' con 'circuit_lengths' a trav칠s de 'circuitRef'
circuits = pd.merge(circuits, circuit_lengths_df, on='circuitRef', how='left')

# Unir 'results_races_drivers' con 'circuits' para obtener la longitud del circuito
results_races_drivers = pd.merge(results_races_drivers, circuits[['circuitId', 'circuit_length_km']], on='circuitId', how='left')

# Calcular distancia total recorrida por cada piloto en cada carrera
results_races_drivers['distancia_total_km'] = results_races_drivers['laps'] * results_races_drivers['circuit_length_km']

# Calcular tiempo en horas, evitando divisi칩n por cero y manejando valores faltantes
results_races_drivers['tiempo_horas'] = results_races_drivers['milliseconds'] / (1000 * 60 * 60)
results_races_drivers['tiempo_horas'].replace(0, np.nan, inplace=True)  # Evitar divisi칩n por cero

# Calcular velocidad promedio en km/h
results_races_drivers['velocidad_promedio_kmh'] = results_races_drivers['distancia_total_km'] / results_races_drivers['tiempo_horas']

# ---------------------------
# Seleccionar variables para el an치lisis de correlaci칩n
corr_variables = {
    'Posici칩n de salida (Grid)': 'grid',
    'Posici칩n final': 'positionOrder',
    'Puntos obtenidos': 'points',
    'Vueltas completadas': 'laps',
    'Tiempo total de carrera (ms)': 'milliseconds',
    'Velocidad de vuelta m치s r치pida': 'fastestLapSpeed',
    'Edad del piloto': 'edad_piloto',
    'N칰mero de pit stops': 'num_pit_stops',
    'Posici칩n en clasificaci칩n': 'posicion_clasificacion',
    'Distancia total recorrida (km)': 'distancia_total_km',
    'Velocidad promedio (km/h)': 'velocidad_promedio_kmh'
}

# Extraer los datos para las variables seleccionadas
corr_data = results_races_drivers[list(corr_variables.values())]

# Convertir columnas a num칠ricas y manejar valores faltantes
corr_data = corr_data.apply(pd.to_numeric, errors='coerce')

# Verificar cu치ntos datos tenemos antes de eliminar filas con NaN
st.write(f"Total de registros antes de eliminar NaNs: {len(corr_data)}")

# Eliminar filas donde todas las variables son NaN
corr_data = corr_data.dropna(how='all')

# Eliminar columnas con todos los valores NaN
corr_data = corr_data.dropna(axis=1, how='all')

# Verificar cu치ntos datos tenemos despu칠s de eliminar filas con NaN
st.write(f"Total de registros despu칠s de eliminar NaNs: {len(corr_data)}")

if corr_data.empty:
    st.warning("No hay datos suficientes para generar la matriz de correlaci칩n.")
else:
    # ---------------------------
    # Matriz de Correlaci칩n General
    st.write("## Matriz de Correlaci칩n General")

    corr_matrix = corr_data.corr()

    # Actualizar nombres de columnas a espa침ol
    inverse_corr_variables = {v: k for k, v in corr_variables.items()}
    corr_matrix.rename(columns=inverse_corr_variables, inplace=True)
    corr_matrix.rename(index=inverse_corr_variables, inplace=True)

    fig, ax = plt.subplots(figsize=(12, 10))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)
    st.pyplot(fig)

    st.markdown("""
    La matriz de correlaci칩n nos muestra las relaciones entre diferentes variables en las carreras de F칩rmula 1.
    """)

    # ---------------------------
    # An치lisis de Correlaciones Espec칤ficas

    st.write("## An치lisis de Correlaciones Espec칤ficas")

    # Opciones de variables para el usuario
    variable_options = list(corr_variables.keys())

    var_x = st.selectbox('Seleccione la variable en el eje X', variable_options, key='var_x')

    # Excluir la variable seleccionada en var_x de las opciones en var_y
    var_y_options = [option for option in variable_options if option != var_x]

    var_y = st.selectbox('Seleccione la variable en el eje Y', var_y_options, key='var_y')

    x = corr_variables[var_x]
    y = corr_variables[var_y]

    # Preparar datos para el scatter plot
    scatter_data = corr_data[[x, y]].dropna()

    if scatter_data.empty:
        st.warning("No hay datos suficientes para generar el gr치fico de dispersi칩n.")
    else:
        # Crear scatter plot
        fig_scatter, ax_scatter = plt.subplots()
        sns.scatterplot(data=scatter_data, x=x, y=y, ax=ax_scatter)
        ax_scatter.set_xlabel(var_x)
        ax_scatter.set_ylabel(var_y)
        ax_scatter.set_title(f'{var_y} vs {var_x}')
        st.pyplot(fig_scatter)

        # Calcular coeficiente de correlaci칩n
        corr_coef = scatter_data[x].corr(scatter_data[y])
        st.write(f"**Coeficiente de correlaci칩n de Pearson entre {var_x} y {var_y}: {corr_coef:.2f}**")

        # Interpretaci칩n b치sica
        if corr_coef > 0.5:
            st.write("Existe una **correlaci칩n positiva fuerte** entre las variables seleccionadas.")
        elif corr_coef > 0.3:
            st.write("Existe una **correlaci칩n positiva moderada** entre las variables seleccionadas.")
        elif corr_coef > 0.1:
            st.write("Existe una **correlaci칩n positiva d칠bil** entre las variables seleccionadas.")
        elif corr_coef < -0.5:
            st.write("Existe una **correlaci칩n negativa fuerte** entre las variables seleccionadas.")
        elif corr_coef < -0.3:
            st.write("Existe una **correlaci칩n negativa moderada** entre las variables seleccionadas.")
        elif corr_coef < -0.1:
            st.write("Existe una **correlaci칩n negativa d칠bil** entre las variables seleccionadas.")
        else:
            st.write("No existe una correlaci칩n significativa entre las variables seleccionadas.")

    # ---------------------------
    # An치lisis Predefinidos

    st.write("## An치lisis Predefinidos")

    # Funci칩n para generar an치lisis predefinidos
    def analizar_correlacion(var_x_name, var_y_name):
        x_var = corr_variables[var_x_name]
        y_var = corr_variables[var_y_name]
        data = corr_data[[x_var, y_var]].dropna()
        if data.empty:
            st.write(f"No hay datos suficientes para analizar {var_x_name} vs {var_y_name}.")
            return
        corr_coef = data[x_var].corr(data[y_var])
        st.write(f"**Coeficiente de correlaci칩n de Pearson:** {corr_coef:.2f}")
        fig, ax = plt.subplots()
        sns.scatterplot(data=data, x=x_var, y=y_var, alpha=0.5, ax=ax)
        ax.set_xlabel(var_x_name)
        ax.set_ylabel(var_y_name)
        ax.set_title(f'{var_y_name} vs {var_x_name}')
        st.pyplot(fig)
        return corr_coef

    # 1. Correlaci칩n entre posici칩n de salida y posici칩n final
    st.write("### 1. Posici칩n de salida vs Posici칩n final")
    corr_gp_fp = analizar_correlacion('Posici칩n de salida (Grid)', 'Posici칩n final')
    st.markdown("""
    Podemos observar una **correlaci칩n positiva** entre la posici칩n de salida y la posici칩n final, lo que indica que los pilotos que empiezan en posiciones delanteras tienden a terminar en mejores posiciones.
    """)

    # 2. Correlaci칩n entre n칰mero de pit stops y posici칩n final
    st.write("### 2. N칰mero de pit stops vs Posici칩n final")
    corr_np_fp = analizar_correlacion('N칰mero de pit stops', 'Posici칩n final')
    st.markdown("""
    Existe una **correlaci칩n positiva d칠bil** entre el n칰mero de pit stops y la posici칩n final. Esto sugiere que m치s pit stops pueden estar asociados con posiciones finales m치s bajas, posiblemente debido al tiempo perdido en paradas adicionales.
    """)

    # 3. Correlaci칩n entre edad del piloto y puntos obtenidos
    st.write("### 3. Edad del piloto vs Puntos obtenidos")
    corr_age_points = analizar_correlacion('Edad del piloto', 'Puntos obtenidos')
    st.markdown("""
    La correlaci칩n entre la edad del piloto y los puntos obtenidos es **d칠bil**. Esto indica que no hay una relaci칩n significativa entre la edad y el rendimiento en t칠rminos de puntos en una carrera individual.
    """)

    # 4. Correlaci칩n entre posici칩n en clasificaci칩n y posici칩n final
    st.write("### 4. Posici칩n en clasificaci칩n vs Posici칩n final")
    corr_qp_fp = analizar_correlacion('Posici칩n en clasificaci칩n', 'Posici칩n final')
    st.markdown("""
    Existe una **correlaci칩n positiva fuerte** entre la posici칩n en clasificaci칩n y la posici칩n final. Esto indica que una buena posici칩n en clasificaci칩n suele traducirse en una mejor posici칩n al final de la carrera.
    """)
